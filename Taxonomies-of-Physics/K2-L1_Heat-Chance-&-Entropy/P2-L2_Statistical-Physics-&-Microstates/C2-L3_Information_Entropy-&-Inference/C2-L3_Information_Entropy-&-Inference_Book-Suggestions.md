# C2 Information, Entropy & Inference — Book Suggestions

Information theory reinterprets entropy as a measure of uncertainty. These books show how inference, coding, and Bayesian reasoning interface with physical entropy and data-driven predictions.

## Entropy & Coding
- *Elements of Information Theory* — Thomas M. Cover & Joy A. Thomas. Presents Shannon entropy, coding theorems, and mutual information.
- *Information Theory, Inference, and Learning Algorithms* — David J. C. MacKay. Blends coding intuition with Bayesian inference and machine learning applications.

## Maximum Entropy Methods
- *Probability Theory: The Logic of Science* — E. T. Jaynes. Derives statistical mechanics as a maximum-entropy inference framework.
- *Maximum Entropy and Bayesian Methods* — John Skilling (ed.). Collects case studies using entropy maximization for inverse problems and data fusion.

## Stochastic Inference
- *Bayesian Data Analysis* — Andrew Gelman et al.. Explains hierarchical models, priors, and posterior computation relevant to inference-driven entropy calculations.
- *Information Physics* — Robert B. Laughlin. Connects informational entropy to physical laws and measurement limits.
